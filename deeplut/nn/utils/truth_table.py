import torch
import math
import numpy as np
import bisect
import random
import itertools
import copy



def generate_truth_table(k: int, tables_count: int, device: str) -> torch.Tensor:
    
    """This function generate truth tables with size of k * (2**k) * tables_count

    Args:
        k (int): truth table power
        tables_count (int): number of truth table repetition
        device (str): target device of the result

    Returns:
        torch.Tensor: 2d torch tensor with k*tables_count rows and (2**k) columns 
    """
    
    table = torch.from_numpy(np.array(list(itertools.product([-1, 1], repeat=k)))).T
    return torch.vstack([table] * tables_count).to(device)

def reduce_truth_table(k: int, table: torch.Tensor, device: str) -> torch.Tensor:
    """This function reduce truth table generated by generate_truth_table by multiply each consecutive k lines

    Args:
        k (int): truth table power
        table (torch.Tensor): Nd array where truth table represented in last 2d
        device (str): target device of the results

    Returns:
        torch.Tensor: Nd torch tensor -dims count not changing- reduced number of rows in the table by k
    """
    result = torch.ones_like(table)
    result = result[...,0::k,:]
    for i in range(k):
        result = result * table[...,i::k,:]
    return result.to(device)

def generate_input_mask_expanded(k, in_size, out_size, device):
    expand_mask = torch.zeros((out_size * in_size * k, 1), dtype=torch.int64).to(device)
    for j in range(out_size):
        for i in range(in_size):
            _from = torch.arange(k) + (i * k) + (j * in_size * k)
            _to = generate_random(in_size, i, k - 1, device).reshape(-1, 1)
            expand_mask[_from] = _to
    return expand_mask

def generate_input_mask_minimal(k, in_size, out_size, device):
    tables_count = math.ceil(in_size/k)
    expand_mask = torch.from_numpy(np.arange(tables_count*k*out_size)%in_size).to(device)
    return expand_mask

def generate_input_mask_shallow(k, in_size, number_of_tables, device):
    expanded_mask_size = number_of_tables * k
    result = np.random.choice(in_size, expanded_mask_size)
    return torch.from_numpy(result).long().to(device)


def generate_input_mask(k, in_size, out_size, device, minimal):
  if minimal:
    return generate_input_mask_minimal(k, in_size, out_size, device)
  else:
    return generate_input_mask_expanded(k, in_size, out_size, device)

